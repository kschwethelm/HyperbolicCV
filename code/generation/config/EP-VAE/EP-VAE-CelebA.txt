# python code/generation/train.py -c generation/config/EP-VAE/EP-VAE-CelebA.txt

# Output settings
exp_name = EP-VAE-CelebA
#output_dir = generation/output

# General settings
device = cuda:0
dtype = float32
seed = 1
#load_checkpoint = generation/output/EP-VAE-CelebA

# General training hyperparameters
num_epochs = 70
batch_size = 100
lr = 5e-4
weight_decay = 0
optimizer = RiemannianAdam
use_lr_scheduler = True
lr_scheduler_step = 50
lr_scheduler_gamma = 0.1

# KL Loss hyperparameters
kl_coeff = 0.09

# General validation/testing hyperparameters
batch_size_test = 512
calc_fid_val = True
batch_size_fid_inception = 512

# General VAE hyperparameters
model = EP-VAE
enc_layers = 4
dec_layers = 4
z_dim = 64
initial_filters = 64

# Hyperbolic manifold settings
embed_K = 0.1
#learn_K = True

# Dataset settings
dataset = CelebA
